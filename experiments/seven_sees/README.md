## seven-sees

This experiment is to use the CSN backbone to create a multimodal model that uses rgb, flow, depth, pose, right hand crop, left hand crop and face crop.

### Dataset setup

The instructions for setting up the preprocessed multimodal data can be found [here](https://github.com/UoA-CARES/sign-language-summer-research/tree/main/setup/wlasl/multimodal).

### Multimodal Checkpoints
Make sure to download the checkpoints from [here](https://uoa-my.sharepoint.com/:f:/r/personal/stas444_uoa_auckland_ac_nz/Documents/Sign%20Language%20Summer%20Project/Checkpoints/seven_sees_multistream_csn_r50_32x2x1_wlasl100?csf=1&web=1&e=5OEE5i) and save them in the same ```./seven_sees``` directory.
