
Epoch [1][5/223], lr: 0.00000e+00, loss: 0.17448
Epoch [1][10/223], lr: 0.00000e+00, loss: 9.5536e-06
Epoch [1][15/223], lr: 0.00000e+00, loss: 3.8743e-08
Epoch [1][20/223], lr: 0.00000e+00, loss: 0.16734
Epoch [1][25/223], lr: 0.00000e+00, loss: 5.0664e-08
Epoch [1][30/223], lr: 0.00000e+00, loss: 0.12456
Epoch [1][35/223], lr: 0.00000e+00, loss: 0.65512
Epoch [1][40/223], lr: 0.00000e+00, loss: 1.1623e-07
Epoch [1][45/223], lr: 0.00000e+00, loss: 0.070086
Epoch [1][50/223], lr: 0.00000e+00, loss: 0.00037368
Epoch [1][55/223], lr: 0.00000e+00, loss: 3.8293e-06
Epoch [1][60/223], lr: 0.00000e+00, loss: 0.11261
Epoch [1][65/223], lr: 0.00000e+00, loss: 0.0017521
Epoch [1][70/223], lr: 0.00000e+00, loss: 5.9605e-09
Epoch [1][75/223], lr: 0.00000e+00, loss: 1.5033e-05
Epoch [1][80/223], lr: 0.00000e+00, loss: 0.11248
Epoch [1][85/223], lr: 0.00000e+00, loss: 0.00019907
Epoch [1][90/223], lr: 0.00000e+00, loss: 2.396e-06
Epoch [1][95/223], lr: 0.00000e+00, loss: 0.095891
Epoch [1][100/223], lr: 0.00000e+00, loss: 1.1921e-08
Epoch [1][105/223], lr: 0.00000e+00, loss: 0.34465
Epoch [1][110/223], lr: 0.00000e+00, loss: 0.00012528
Epoch [1][115/223], lr: 0.00000e+00, loss: 0.056341
Epoch [1][120/223], lr: 0.00000e+00, loss: 3.8743e-08
Epoch [1][125/223], lr: 0.00000e+00, loss: 3.129e-06
Epoch [1][130/223], lr: 0.00000e+00, loss: 0.0052678
Epoch [1][135/223], lr: 0.00000e+00, loss: 0.18278
Epoch [1][140/223], lr: 0.00000e+00, loss: 3.5166e-07
Epoch [1][145/223], lr: 0.00000e+00, loss: 2.0116e-06
Epoch [1][150/223], lr: 0.00000e+00, loss: 0.0
Epoch [1][155/223], lr: 0.00000e+00, loss: 1.1951e-05
Epoch [1][160/223], lr: 0.00000e+00, loss: 0.00013363
Epoch [1][165/223], lr: 0.00000e+00, loss: 0.25484
Epoch [1][170/223], lr: 0.00000e+00, loss: 8.9407e-09
Epoch [1][175/223], lr: 0.00000e+00, loss: 0.076215
Epoch [1][180/223], lr: 0.00000e+00, loss: 0.00015924
Epoch [1][185/223], lr: 0.00000e+00, loss: 5.9605e-09
Epoch [1][190/223], lr: 0.00000e+00, loss: 2.3842e-08
Epoch [1][195/223], lr: 0.00000e+00, loss: 0.17555
Epoch [1][200/223], lr: 0.00000e+00, loss: 2.9504e-07
Epoch [1][205/223], lr: 0.00000e+00, loss: 1.1662e-05
Epoch [1][210/223], lr: 0.00000e+00, loss: 1.8533e-05
Epoch [1][215/223], lr: 0.00000e+00, loss: 0.077499
Epoch [1][220/223], lr: 0.00000e+00, loss: 5.1583e-06
Evaluating top_k_accuracy...
top1_acc: 0.8256, top5_acc: 0.9419, train_loss: 5.1583e-06
Saving checkpoint at 1 epochs...